# 논문 초안: 어휘 등급 분석 시스템의 아키텍처 및 5단계 분석 방법론

본 연구에서 제안하는 시스템은 한국어 텍스트의 어휘 난이도를 정량적으로 측정하기 위해 설계되었다. 한국어는 실질 형태소와 형식 형태소가 결합하는 교착어적 특성과, 띄어쓰기 단위(어절)와 의미 단위(단어)가 일치하지 않는 특성을 가진다. 이러한 언어적 특수성을 고려하여, 본 시스템은 단순한 어휘 매칭을 넘어 형태통사적(Morpho-syntactic) 구조와 문맥적 의미(Semantic Context)를 통합적으로 분석하는 **5단계 분석 파이프라인**을 제안한다.

---

## 1단계: 형태소 분석 (Morphological Analysis)
비정형 텍스트를 분석 가능한 최소 의미 단위로 분절하는 기초 단계이다. 본 시스템은 한국어 형태소 분석기 'Kiwi'를 사용하여 입력된 문장(Sentence)을 형태소(Morpheme) 단위의 토큰 시퀀스로 변환한다. 이 과정에서 단순한 토큰화(Tokenization)를 넘어, 각 형태소의 표제어(Lemma)와 품사 태그(POS Tag)를 식별하여 문장의 문법적 구조를 1차적으로 파악한다. 이는 이후 단계에서 수행될 어휘 판별의 기반이 되며, 어절 단위 분석이 가지는 한계를 극복하게 한다.

## 2단계: 어휘 리소스 매핑 (Lexical Resource Mapping)
추출된 형태소 정보를 교육용 등급 데이터와 연동하기 위해, 이질적인 데이터 소스를 표준화된 구조로 매핑하는 단계이다.
시스템은 세 가지 특화된 매핑 테이블을 통해 형태소 분석 결과와 어휘 데이터베이스 간의 연결성을 확보한다.
*   **어휘 지도(Word Map)**: 실질적인 의미를 지닌 자립 형태소를 대상으로 한다. 명사류(NNG, NNP, NR, NP), 용언류(VV, VA, VX), 관형사(MM), 부사(MAG) 등의 품사 태그를 가진 어휘가 이곳에 매핑된다. 검색 재현율(Recall)을 높이기 위해 세분화된 품사를 범주화된 키(N, V)로 변환하여 인덱싱하는 일반화 전략을 사용한다. 또한, ‘수도01(Capital)’, ‘수도02(Water)’와 같이 숫자로 구분된 동음이의어는 검색 등 식별(Identification)이 필요한 상황에서는 원형을 유지하지만, 형태소 분석 결과와의 매칭(Mapping)을 위한 인덱싱 과정에서는 숫자를 제거한 정제된 형태(‘수도’)로 변환된다. 이를 통해 입력 문장의 단순한 형태소가 데이터베이스의 모든 관련 동음이의어 후보군과 빠짐없이 연결될 수 있도록 보장한다.
*   **문법 지도(Grammar Map)**: 문법적 관계를 나타내거나 어휘를 파생시키는 형식 형태소를 대상으로 한다. 조사(JKS, JKO 등), 어미(EC, EF 등), 접사(XSN, XSV)가 주된 매핑 대상이다.
*   **관용구/문법 표현 지도(Expression Map)**: 개별 형태소 단위가 아닌, 둘 이상의 형태소가 결합된 다어절 표현(Multi-word Expressions)을 대상으로 한다. 이 지도는 시스템 초기화 시점에 문법 데이터베이스의 **대표형**뿐만 아니라 **관련형(이형태)**까지 포함하여, 띄어쓰기가 있거나 ‘표현’으로 분류된 모든 변이형을 추출해 동적으로 생성된다. 이때 입력 문장 분석과 동일한 형태소 분석기(Kiwi)를 통해 선행 분석(Pre-analysis)을 수행하여, 데이터를 형태소 단위로 정규화하여 저장한다. 특히 활용(Inflection)이 자유로운 용언이나 표현의 경우, 다양한 종결 어미와의 결합 가능성을 열어두기 위해 **사전 등재형의 종결어미 ‘-다’를 제거한 어간(Stem) 형태**로 인덱싱한다. 생성된 맵은 첫 번째 형태소를 키(Key)로, 후속 형태소들의 서열(Sequence)을 값(Value)으로 구조화하여, 3단계 구문 패턴 매칭 시 입력 문장과의 정밀한 형태론적 대응을 보장한다.

## 3단계: 구문 및 복합어 정제 (Syntactic & Compound Refinement)
1차 형태소 분석 결과를 바탕으로, 인접한 형태소들을 재조합하여 실질적인 의미 단위를 복원하는 심화 분석 단계이다. 이 단계에서는 **'우선순위 기반 병합 알고리즘(Priority-based Merging Algorithm)'**을 적용한다.
1.  **구문 패턴 매칭(Syntactic Pattern Matching)**: 최우선적으로 '표현 지도(Expression Map)'를 참조하여 일련의 형태소 시퀀스가 특정 문법 표현 패턴과 일치하는지 검사한다.
    *   **순회 조회(Traversal)**: 입력된 문장의 형태소 리스트를 순차적으로 탐색한다.
    *   **키 매칭(Key Matching)**: 현재 형태소가 표현 지도의 키(Start Token)와 일치하는지 확인한다.
    *   **전방 탐색(Lookahead)**: 키가 일치할 경우, 지도의 값(Value)에 정의된 후속 형태소 서열이 실제 문장의 다음 형태소들과 정확히 일치하는지 비교한다.
    *   **병합(Merging)**: 전체 서열이 일치하면 해당 형태소들을 모두 묶어 하나의 '문법적 표현' 단위로 병합하고 등급을 부여한다.
2.  **복합어 및 파생어 결합(Compound & Derivational Merging)**: 인접한 2-gram 형태소 쌍에 대해 전방 탐색(Lookahead)을 수행하여, 파생어(예: 명사+접미사)나 합성어가 사전에 등재되어 있는지 확인한다.
3.  **용언 원형 복원 (Predicate Lemma Reconstruction)**: '신선하고'와 같이 활용된 용언(동사/형용사)이 입력될 경우, 형태소 분석된 어간(Stem)에 기본 종결어미 '-다'를 부착하여 사전 등재형(Lemma)을 재구성함으로써, '신선하다'와 같은 표제어와 정확히 매칭되도록 처리한다.
4.  **오류 보정**: 형태소 분석기가 과도하게 분절하거나 잘못 태깅한 케이스를 문맥과 사전에 기반해 교정한다.

## 4단계: 문맥적 의미 중의성 해소 (Contextual Semantic Disambiguation)
형태와 품사가 동일하지만 문맥에 따라 다른 등급을 갖는 동음이의어(Homonyms) 문제를 해결하는 단계이다.
규칙 기반(Rule-based) 접근으로는 해결이 불가능한 이 문제를 다루기 위해, 본 시스템은 거대언어모델(LLM)을 활용한 **'문맥 인지 판별 모델'**을 도입한다. 프로파일링 과정에서 복수의 후보 의미가 존재하는 어휘가 발견될 경우, 시스템은 전체 문맥과 후보군을 LLM에 질의한다. LLM은 문장의 의미적 맥락을 추론하여 가장 적합한 어휘 ID를 선정하며, 이를 통해 '타다(Ride, 1급)'와 '타다(Burn, 3급)'와 같은 미묘한 의미 차이를 정밀하게 구분해낸다.

## 5단계: 정량적 등급 프로파일링 (Quantitative Grade Profiling)
확정된 어휘 및 문법 정보를 종합하여 텍스트의 어휘 복잡도를 나타내는 핵심 지표(Key Metrics)를 산출하는 최종 단계이다. 이 단계에서는 시각화 이전의 순수 분석 데이터가 생성된다.
*   **등급별 빈도 집계 (Grade Frequency Calculation)**: 1급부터 6급까지 각 등급에 해당하는 어휘의 개수를 정량적으로 집계한다. 이때 분석의 정확성을 위해 문장 부호나 특수 문자는 '기타' 범주로 분류하고, 숫자는 전체 어휘 수(Total Count)에는 포함하되 어휘 등급 산정에서는 제외하는 조건부 집계 로직을 적용한다.
*   **최고 난이도 결정 (Max Level Determination)**: 텍스트 내 식별된 유의미한 등급 어휘 중 가장 높은 급수를 도출한다. 이는 해당 텍스트를 이해하기 위해 요구되는 최소한의 어휘 능력을 대변하는 지표로 활용된다.
*   **미분류 비율 산출 (Unclassified Ratio)**: 전체 형태소 중 등급 데이터베이스에 매핑되지 않은(Not Rated) 어휘의 비율을 계산하여, 텍스트 내 고유명사나 전문용어의 비중을 간접적으로 파악할 수 있는 데이터를 제공한다.

이러한 5단계 파이프라인은 형태소(Micro) 단위에서 구문 및 문맥(Macro) 단위로 분석 범위를 점진적으로 확장함으로써, 한국어 어휘 등급 분석의 정확도와 신뢰성을 획기적으로 향상시킨다.
